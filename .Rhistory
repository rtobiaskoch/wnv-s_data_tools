calc_vi <- function(data, grp_var, rm_zone = c("BC")) {
#check packages
#-------------------------------------------------------------------------------
#FOR BOTH ABUNDANCE AND PIR
if (!require("tidyverse")) install.packages("tidyverse")
#FOR PIR
if (!require("PooledInfRate")) {
install.packages("devtools")
devtools::install_github("https://github.com/CDCgov/PooledInfRate",build_vignettes = TRUE)
}
#check inputs
#-------------------------------------------------------------------------------
if ("csu_id" %in% grp_var) {
stop("Cannot calculate abundance using csu_id as a grouping variable.
CSU IDs represent individual mosquito pools, not trap-level data.")
}
if(any(!grp_var %in% colnames(data))) {
stop("one or more of your your grouping variables (grp_var) do not exist in the data")
}
# Create base grouping variables
#-------------------------------------------------------------------------------
base_vars <- c("year", "week", "trap_id")
# Combine with user-provided grp_var and remove duplicates
grp_var1 <- unique(c(base_vars, grp_var))
# Convert grouping variables to symbols for use in dplyr
grp_vars_sym <- syms(grp_var1)
grp_var_final <- syms(grp_var)
# Calc abundance
#-------------------------------------------------------------------------------
# First summarization by year, week, trap_id, and grp_var
df_abund <- data %>%
filter(method == "L") %>%  # only run on Light Traps
filter(!zone %in% rm_zone) %>%  # remove specified zones
group_by(!!!grp_vars_sym) %>%
summarize(
n_trap = n_distinct(trap_id),
mosq_L0 = sum(total, na.rm = TRUE),
.groups = 'drop'
)
# Second summarization by just grp_var
df_abund <- df_abund %>%
group_by(!!!grp_var_final) %>%
summarize(
mosq_L = sum(mosq_L0),
n_trap = sum(n_trap),
abund = round(mosq_L/n_trap, 4),
abund_sd = if_else(n_trap > 1,
round(sd(mosq_L0), 2),
0),
.groups = 'drop') %>%
mutate(abund_lci = round(abund - (1.96*(abund_sd/n_trap^0.5)),4),
abund_uci = round(abund + (1.96*(abund_sd/n_trap^0.5)),4)
) %>%
mutate(abund_lci = if_else(abund_lci < 0, 0, abund_lci)) %>%
mutate(across(all_of(grp_var), as.character)) #ensure left_join will work
#END OF ABUNDANCE
# Calc PIR from the pool data
#-------------------------------------------------------------------------------
df_pir = data %>%
filter(!zone %in% rm_zone) %>%
tidyr::unite(col = "grp", all_of(grp_var), sep = "_", remove = FALSE)
mle = PooledInfRate::pIR(test_code ~ total|grp, data =   df_pir, pt.method = "firth")
df_pir = as.data.frame(mle) %>%
separate(grp,
into = {{grp_var}},
sep = "_") %>%
mutate(pir = round(P,4),
pir_lci = round(Lower,4),
pir_uci = round(Upper,4)
) %>%
mutate(across(all_of(grp_var), as.character)) %>% #ensure left_join will work
select(-P, -Upper, -Lower)
#END OF PIR
# Calc VI by combining abundance and PIR
#-------------------------------------------------------------------------------
left_join(df_abund, df_pir, by = grp_var) %>%
mutate(vi = round(abund * pir, 4),
vi_lci = round(abund * pir_lci, 4),
vi_uci = round(abund * pir_uci, 4))
} #end of function
calc_vi(database, c("trap_id"))
# Define the function to calculate abundance
calc_vi <- function(data, grp_var, rm_zone = c("BC")) {
#check packages
#-------------------------------------------------------------------------------
#FOR BOTH ABUNDANCE AND PIR
if (!require("tidyverse")) install.packages("tidyverse")
#FOR PIR
if (!require("PooledInfRate")) {
install.packages("devtools")
devtools::install_github("https://github.com/CDCgov/PooledInfRate",build_vignettes = TRUE)
}
#check inputs
#-------------------------------------------------------------------------------
if ("csu_id" %in% grp_var) {
stop("Cannot calculate abundance using csu_id as a grouping variable.
CSU IDs represent individual mosquito pools, not trap-level data.")
}
if(any(!grp_var %in% colnames(data))) {
stop("one or more of your your grouping variables (grp_var) do not exist in the data")
}
# Create base grouping variables
#-------------------------------------------------------------------------------
base_vars <- c("year", "week", "trap_id")
# Combine with user-provided grp_var and remove duplicates
grp_var1 <- unique(c(base_vars, grp_var))
# Convert grouping variables to symbols for use in dplyr
grp_vars_sym <- syms(grp_var1)
grp_var_final <- syms(grp_var)
# Calc abundance
#-------------------------------------------------------------------------------
# First summarization by year, week, trap_id, and grp_var
df_abund <- data %>%
filter(method == "L") %>%  # only run on Light Traps
filter(!zone %in% rm_zone) %>%  # remove specified zones
group_by(!!!grp_vars_sym) %>%
summarize(
n_trap = n_distinct(trap_id),
mosq_L0 = sum(total, na.rm = TRUE),
.groups = 'drop'
)
# Second summarization by just grp_var
df_abund <- df_abund %>%
group_by(!!!grp_var_final) %>%
summarize(
mosq_L = sum(mosq_L0),
n_trap = sum(n_trap),
abund = round(mosq_L/n_trap, 4),
abund_sd = if_else(n_trap > 1,
round(sd(mosq_L0), 2),
0),
.groups = 'drop') %>%
mutate(abund_lci = round(abund - (1.96*(abund_sd/n_trap^0.5)),4),
abund_uci = round(abund + (1.96*(abund_sd/n_trap^0.5)),4)
) %>%
mutate(abund_lci = if_else(abund_lci < 0, 0, abund_lci)) %>%
mutate(across(all_of(grp_var), as.character)) #ensure left_join will work
#END OF ABUNDANCE
# Calc PIR from the pool data
#-------------------------------------------------------------------------------
df_pir = data %>%
filter(!zone %in% rm_zone) %>%
tidyr::unite(col = "grp", all_of(grp_var), sep = "_", remove = FALSE)
mle = PooledInfRate::pIR(test_code ~ total|grp, data =   df_pir, pt.method = "firth")
df_pir = as.data.frame(mle) %>%
separate(grp,
into = {{grp_var}},
sep = "_") %>%
mutate(pir = round(P,4),
pir_lci = round(Lower,4),
pir_uci = round(Upper,4)
) %>%
mutate(across(all_of(grp_var), as.character)) %>% #ensure left_join will work
select(-P, -Upper, -Lower)
#END OF PIR
# Calc VI by combining abundance and PIR
#-------------------------------------------------------------------------------
full_join(df_abund, df_pir, by = grp_var) %>%
mutate(vi = round(abund * pir, 4),
vi_lci = round(abund * pir_lci, 4),
vi_uci = round(abund * pir_uci, 4))
} #end of function
t = calc_vi(database, c("trap_id"))
View(t)
list2env(readRDS(config_params_file),
envir = .GlobalEnv)
#Config
rm(list = ls())
suppressMessages({
if (!require("pacman")) install.packages("pacman")
pacman::p_unload()
pacman::p_load(googlesheets4, googledrive, rio, readxl, openxlsx, googledrive, #importing and exporting
tidyverse, janitor, lubridate, rquery, #manipulation
PooledInfRate, #analysis
ggpubr, wesanderson, paletteer, leaflet, patchwork s# plotting
pacman::p_load(googlesheets4, googledrive, rio, readxl, openxlsx, googledrive, #importing and exporting
tidyverse, janitor, lubridate, rquery, #manipulation
PooledInfRate, #analysis
ggpubr, wesanderson, paletteer, leaflet, patchwork# plotting
)
suppressMessages({
if (!require("pacman")) install.packages("pacman")
pacman::p_unload()
pacman::p_load(googlesheets4, googledrive, rio, readxl, openxlsx, googledrive, #importing and exporting
tidyverse, janitor, lubridate, rquery, #manipulation
PooledInfRate, #analysis
ggpubr, wesanderson, paletteer, leaflet, patchwork# plotting
)
})
#Config
rm(list = ls())
suppressMessages({
if (!require("pacman")) install.packages("pacman")
pacman::p_unload()
pacman::p_load(googlesheets4, googledrive, rio, readxl, openxlsx, googledrive, #importing and exporting
tidyverse, janitor, lubridate, rquery, #manipulation
PooledInfRate, #analysis
ggpubr, wesanderson, paletteer, leaflet, patchwork# plotting
)
})
#>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
#FOLDER NAME CREATE AND CHECK
#>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
#NAMEO OF FOLDERS
folder_input = "1_input"
folder_mid = "2_mid"
folder_output = "3_output"
#CREATE FOLDERS IF THEY DON'T EXIST
if(!dir.exists(folder_input)) {
dir.create(folder_input)
}
if(!dir.exists(folder_mid)) {
dir.create(folder_mid)
}
if(!dir.exists(folder_output)) {
dir.create(folder_output)
}
if(!file.exists(paste0(folder_input, "/config_params.RDS"))) {
#+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
#>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
#DATA PARAMETERS:
#>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
args = commandArgs(trailingOnly = T)
year_filter = as.integer(args[1])
if(!is.integer(year_filter)) {print("your year filter must be numeric")}
week_filter = as.integer(args[2])
if(!is.integer(year_filter)) {print("your week filter must be numeric")}
week_filter_yr= 23:week_filter
week_filter_hx = 23:37
year_filter_hx = seq(year_filter-11, year_filter-1, by = 1)
#if drive doesn't have a token then have user authorize
if(!drive_has_token()) {
googledrive::drive_auth()
}
fc_zones = c("NE", "SE", "NW", "SW")
non_fc_zones = c("LV", "BC", "BE")
all_zones = c("NE", "SE", "NW", "SW", "LV", "BC", "BE")
copy_threshold = 500
rn_threshold = 34000
vi_threshold = 0.75
#+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
#>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
#CODE OPTIONS
#>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
update_trap = "NO"
clean_data = "NO"
fc_zone_filter = "YES"
#+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
#>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
#OUTPUT FILE NAME GENERATION
#>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
if(length(year_filter) > 1){ #if looking at multiple years then create YYYY-YYYY range
fn_year = paste0(min(year_filter), "-", max(year_filter))
} else { #otherwise fn_year stays the same
fn_year = year_filter
}
if(length(week_filter) > 1){ #if looking at multiple years then create YYYY-YYYY range
fn_week = paste0(min(week_filter), "-", max(week_filter))
} else { #otherwise fn_year stays the same
fn_week = week_filter
}
#+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
#>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
#FILE NAMES INPUT
#>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
database_gsheet_key = "12Mf-w9I9NHTTDjzEPRoxUE08ka4WZ6RE-RM1s-FW7qA"
trap_gsheet_key = "1Jna3Bu47gjBWWz5vCoel4ksa-LBuo8R3zVfQYFl73wI"
trap_malfunction_key = "1dsTyvZoCN6NUJlTcDLINMfxuGZdJuP2ADpn8noQwL6Q"
#trap_active_key = "1SA_PE74KLH6_jG3yR49e8py1uXgb_C02Q3Iz9MWivrY"
standards_key = "1bSMYQ4bZ9uBfrOQ6ylsegNmmGYdf9YFVbxB4qBhnFQo"
routine_trap_tl_key = "1kIOqx6CldJ3ivXu9_ws60qqxrlLSmjHRz_tkv03vhqs"
#google drive file names
fn_gdrive_database = "wnv-s_database"
#+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
#weekly input
fn_datasheet_input = paste0(folder_input, "/datasheet") #replaced vdci and cdc input because also have boulder so all in one place
fn_platemap = paste0(folder_input, "/platemap")
fn_pcr = paste0(folder_input, "/pcr")
fn_trap_malfunction = paste0(folder_input, "/trap_malfunction.csv")
fn_trap_active = paste0(folder_input, "/trap_active.csv")
fn_trap = paste0(folder_input, "/foco_trap.csv")
fn_database_input = paste0(folder_input, "/wnv-s_database.csv")
#>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
# FILE NAMES MID
#>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
fn_database_update = paste0(folder_mid, "/wnv-s_database_update.csv")
fn_datasheet_clean = paste0(folder_mid,"y",fn_year, "_", "w",fn_week, "_datasheet.csv")
fn_datasheet_clean_test = paste0(folder_mid,"y",fn_year, "_", "w",fn_week, "_datasheet_test.csv")
fn_weekly_input_format_mid = paste0(folder_mid, "/weekly_1_input_format_mid.RData")
fn_cq_out = paste0(folder_mid,"y",fn_year, "_", "w",fn_week, "_platemap.csv")
fn_abund_out = paste0(folder_mid,"y",fn_year, "_", "w",fn_week, "_abundance")
fn_pools_mid = paste0(folder_mid,"y",fn_year, "_", "w",fn_week, "_pools.csv")
fn_inactive_trap = paste0(folder_mid, "/inactive_traps.csv")
fn_func_trap = paste0(folder_mid, "/functional_traps.csv")
fn_max_trap_yr = paste0(folder_mid, "/max_trap_zone_yr.csv")
fn_trap_p_wk = paste0(folder_mid, "/trap_p_wk.csv")
#>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
#FILE NAMES OUTPUT
#>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
fn_gdrive_archive = paste0("wnv-s_database_pre_y",year_filter, "_w", week_filter,".gsheet")
fn_data_output = paste0(folder_output,"y",fn_year, "_", "w",fn_week, "_data_update.csv")
fn_weekly_input_format = paste0(folder_output, "weekly_1_input_format.csv")
fn_stds_ctrl_slev_bird = paste0(folder_output, "std_ctrl_slev_bird.csv")
fn_non_database_sample = paste0(folder_output, "non_database_samples(std-ctrl-bird-etc).csv")
#+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
#>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
#SELECTION COLUMN SETTINGS
#>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
trap_col = c("zone", "lat", "long")
input_data_col = c("csu_id", "trap_id", "year", "week", "trap_date",
"county", "method", "spp", "total", "test_code", "zone")
data_col = c("csu_id", "trap_id", "year", "week", "trap_date",
"county", "method", "genus", "spp", "sex", "no_gravid",
"no_deplete", "total", "test_code", "seq", "cq",
"zone", "lat", "long")
database_col = c( "csu_id", "trap_id", "year", "week", "trap_date", "county", "method", "spp",
"total", "test_code", "cq", "copies_WNV", "seq", "zone", "cq", "lat", "long")
pcr_check_col <- c("csu_id", "test_code", "ct_threshold", "plate", "copies_SLEV", "copies_WNV", "cq_SLEV", "cq")
class_col <- c("csu_id" = "character",
"trap_id" = "character",
"year" = "numeric",
"week" = "numeric",
"trap_date" = "character",
"county" = "character",
"method" = "character",
"genus" = "character",
"spp" = "character",
"sex" = "logical",
"no_gravid" = "numeric",
"no_deplete" = "numeric",
"total" = "numeric",
"test_code" = "numeric",
"seq" = "numeric",
"cq" = "numeric",
"zone" = "character",
"lat" = "numeric",
"long" = "numeric")
rename_col <- c("csu_id" = "CSU Pool Number (CMC Enters)" ,
"trap_id" = "Collection Site       (Trap ID)",
"year" = "Year",
"week" = "Week",
"trap_date" = "Trap Date",
"county" = "County",
"method" = "L/G",
"genus" = "Genus",
"spp" = "Species",
"sex" = "Sex",
"no_gravid" = "No. Gravid",
"no_deplete" = "No. Deplete",
"total" = "Total",
"test_code" = "Test Code (CSU Enters)" ,
"zone" = "Zone")
weekly_input_report_format <- c(
"Year",
"CSU Pool Number (CMC Enters)",
"IDA Pool (CSU Enters, Leave Blank)",
"Week",
"Trap Date",
"County",
"Account",
"Collection Site       (Trap ID)" ,
"Zone",
"Method",
"Genus",
"SPP",
"Sex",
"No. Gravid",
"No. Deplete",
"Total",
"Test Code (CSU Enters)",
"Test Result (CSU Enters)",
"Comments"
)
#+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
#>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
#GROUP VARS
#>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
grp_vars = c("year", "week", "zone", "spp")
hx_grp_vars = c("week", "zone")
zone_lvls = c("NW", "NE", "SE","SW", "FC", "LV", "BE", "BC")
non_routine_zones = c("BC")
#>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
#COLOR SETTINGS
#>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
color_palette = wes_palette('Darjeeling1')
# year_col_highlight = "2023"
#
# year_cols_df = data.frame(year = 2000:2050) %>%
#   mutate(year = as.factor(year)) %>%
#   mutate(col = if_else(as.character(year) == year_col_highlight,
#                        year_col_highlight,
#                        "other"))
#
# year_cols = c("2023" = "#c5283d",
#               "other" = "grey50")
#https://coolors.co/palette/fb8b24-d90368-820263
mozzy_pal = c("hx_Tarsalis" = "grey50",
"hx_Pipiens" = "grey30",
"current_Tarsalis" = "#e9724c",
"current_Pipiens" = "#820263")
mozzy_pal2 = c("Pipiens" = "#820263",
"Tarsalis" = "#e9724c",
"All" = "#faa916")
mozzy_pal3 = c("#ffc857", "#e9724c", "#c5283d")
curr_hx_pal = c("current" = "#e9724c",
"hx"      = "grey50")
#+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
all_params <- ls(envir = .GlobalEnv)
# Create a list containing all the values of these objects
all_params_list <- mget(all_params, envir = .GlobalEnv)
saveRDS(all_params_list, paste0(folder_input, "/config_params.RDS"))
} else { #end of if config_params.RDS file exists
list2env(readRDS(paste0(folder_input, "/config_params.RDS")),
envir = .GlobalEnv)
cat(paste0("config file already exists in ", folder_input, "/config_params.RDS", "\n",
"year filter = ", year_filter, "\n",
"week filter = ", week_filter)
)
}
list2env(readRDS(config_params_file),
envir = .GlobalEnv)
gsheet_pull(key_trap_gsheet, "data", fn_trap)
gsheet_pull(key = "1Jna3Bu47gjBWWz5vCoel4ksa-LBuo8R3zVfQYFl73wI",
sheet = "data",
out_fn = "1_input/foco_trap.csv")
#devtools::source_url("https://github.com/rtobiaskoch/TK_useful_functions/blob/main/gsheet_pull.R")
source("0_R/gsheet_pull.R")
gsheet_pull(key = "1Jna3Bu47gjBWWz5vCoel4ksa-LBuo8R3zVfQYFl73wI",
sheet = "data",
out_fn = "1_input/foco_trap.csv")
#>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
#LOAD PACKAGES FOR PIPELINE
#>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
rm(list = ls())
#IF THE CONFIG PARAMS FILE EXISTS US THAT TO DEFINE INPUTS
# ELSE DEFINE THEM HERE
config_params_file = "1_input/config_params.RDS" # <<<<<<<<<<----------------------------------  USER INPUT
if(file.exists(config_params_file)){
list2env(readRDS(config_params_file),
envir = .GlobalEnv)
} else {
#LOAD PACKAGES
suppressMessages({
if (!require("pacman")) install.packages("pacman")
pacman::p_unload()
pacman::p_load(tidyverse, readxl, purrr #manipulation
)
})
#>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
#--------------------------- I N P U T S --------------------------------
#>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
#INPUTS FOR THIS SCRIPT IF CONFIG FILE DOESN'T EXIST
#SUBDIRECTORIES INPUTS
dir_pcr = "1_input/pcr/" # <<<<<<<<<<-------------------------------------------------------------  USER INPUT
dir_platemap= "1_input/platemap/"
#TIME FILTERS
week_filter = 37
year_filter = 2024
#FILENAMES OUTPUT
fn_cq_out = paste0("2_mid","/y",year_filter, "_", "w",week_filter, "_platemap.csv")
#USER DEFINED STATIC DATA PARAMETERS:
copy_threshold = 500
rn_threshold = 34000
#+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
#+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
} # end of if config_params_file exist statement
source("0_R/gsheet_pull_prompt.R")
#>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
#LOAD PACKAGES FOR PIPELINE
#>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
rm(list = ls())
#IF THE CONFIG PARAMS FILE EXISTS US THAT TO DEFINE INPUTS
# ELSE DEFINE THEM HERE
config_params_file = "1_input/config_params.RDS" # <<<<<<<<<<----------------------------------  USER INPUT
if(file.exists(config_params_file)){
list2env(readRDS(config_params_file),
envir = .GlobalEnv)
} else {
#LOAD PACKAGES
suppressMessages({
if (!require("pacman")) install.packages("pacman")
pacman::p_unload()
pacman::p_load(tidyverse, readxl, purrr #manipulation
)
})
source("0_R/gsheet_pull_prompt.R")
#>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
#--------------------------- I N P U T S --------------------------------
#>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
#INPUTS FOR THIS SCRIPT IF CONFIG FILE DOESN'T EXIST
dir_input = "1_input/"
#TIME FILTERS
key_trap_gsheet = "1Jna3Bu47gjBWWz5vCoel4ksa-LBuo8R3zVfQYFl73wI"
fn_trap <- file.path(dir_input, "foco_trap - data.csv")
} # end of if config_params_file exist statement
source("0_R/gsheet_pull_prompt.R")
gsheet_pull_prompt(key_trap_gsheet, "data", fn_trap)
fun_gsheet_pull_prompt(key_trap_gsheet, "data", fn_trap)
fun_gsheet_pull_prompt(filename = fn_trap, "data", key =  key_trap_gsheet)
trap_data = read.csv(fn_trap)
trap_data = read.csv(fn_trap)
# Create a color palette based on the 'zone' column
pal <- colorFactor(palette = "viridis", domain = trap_data$zone)
# Create the Leaflet map
leaflet(trap_data) %>%
addTiles() %>%
addCircleMarkers(
~long, ~lat,
color = ~pal(zone),
popup = ~paste0("Trap ID: ", trap_id, "<br>Zone: ", zone)
) %>%
addLegend("bottomright", pal = pal, values = ~zone, title = "Zone")
